{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "import math\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#www.python-graph-gallery.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNBALANCED_LINK_soy_55_percent_of_data_final_saved_balanced_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "INGREDIENT_TO_REPLACE = 'soy'#'palm oil'#'palm oil'#'peanut'#palm oil'#'palm oil'#'soya'#'peanut'#'palm oil''peanut'#'wheat'#'wheat'#'soya'#\n",
    "USE_STANDARD_DATA = False\n",
    "SAVE_STANDARD_DATA = True\n",
    "USE_FREQUENCY = False\n",
    "MASK = False\n",
    "LOAD_SUB_FROM_FILE = False\n",
    "USE_FREQUENCY = False\n",
    "LOAD_BALANCED_DATA = False\n",
    "STEM = True\n",
    "REPLACE = True\n",
    "REMOVE_REPLACE = False\n",
    "SUBSET_PERC = 0.5\n",
    "perc_for_print = str(SUBSET_PERC).split('.')[1]\n",
    "root_to_standard_data = f'UNBALANCED_LINK_{INGREDIENT_TO_REPLACE}_{perc_for_print}_percent_of_data_final_saved_balanced_dataset.csv'\n",
    "print(root_to_standard_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3172: DtypeWarning: Columns (43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3172: DtypeWarning: Columns (38,39,40,41,42,43,44,45,46,47,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "11000it [00:03, 3640.85it/s]\n",
      "10225it [01:42, 99.41it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4184</td>\n",
       "      <td>BANQUET Frozen Chicken Breast Patties Made Wit...</td>\n",
       "      <td>Banquet</td>\n",
       "      <td>['Grocery', 'Grocery &amp; Gourmet Food', 'Breast ...</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.88</td>\n",
       "      <td>['water', 'sodium bicarbonate', 'yeast', 'corn...</td>\n",
       "      <td>[water, sodiumbicarbon, yeast, cornstarch, whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4487</td>\n",
       "      <td>COLMANS Original English Mustard</td>\n",
       "      <td>Colman's</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'English Mustard', ...</td>\n",
       "      <td>19.73</td>\n",
       "      <td>4.49</td>\n",
       "      <td>['water', 'mustard flour', 'sugar', 'salt', 'w...</td>\n",
       "      <td>[water, mustardflour, sugar, salt, wheatflour,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4137</td>\n",
       "      <td>Against The Grain Three Cheese Pizza</td>\n",
       "      <td>Against The Grain</td>\n",
       "      <td>['Pizza', 'Grocery &amp; Gourmet Food', 'Frozen']</td>\n",
       "      <td>100.32</td>\n",
       "      <td>100.32</td>\n",
       "      <td>['crust tapioca starch', 'milk', 'eggs', 'cano...</td>\n",
       "      <td>[crusttapiocastarch, milk, egg, canolaoil, che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1381</td>\n",
       "      <td>NESTLE COFFEE-MATE Coffee Creamer</td>\n",
       "      <td>Nestle Coffee Mate</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Dairy', ' Cheese &amp;...</td>\n",
       "      <td>22.72</td>\n",
       "      <td>17.48</td>\n",
       "      <td>['water', 'sugar', 'coconut oil', 'sodium case...</td>\n",
       "      <td>[water, sugar, coconutoil, sodiumcasein, dipot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1493</td>\n",
       "      <td>Planters Peanuts</td>\n",
       "      <td>Planters</td>\n",
       "      <td>['Grocery', 'Cooking &amp; Baking', 'Nuts &amp; Trail ...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.95</td>\n",
       "      <td>['peanut andor cottonseed oil', 'peanuts', 'al...</td>\n",
       "      <td>[peanutcottonseoil, peanut, almond, cashew, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10991</th>\n",
       "      <td>9828</td>\n",
       "      <td>Merenda Hazelnut Spread</td>\n",
       "      <td>Pavlidis</td>\n",
       "      <td>['Jams', ' Jellies &amp; Sweet Spreads', 'Grocery ...</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.10</td>\n",
       "      <td>['sugar', 'peanut oil', 'hazelnuts', 'skim mil...</td>\n",
       "      <td>[sugar, peanutoil, hazelnut, milk, cocoa, soy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10992</th>\n",
       "      <td>10380</td>\n",
       "      <td>Honest Syrup</td>\n",
       "      <td>ChocZero</td>\n",
       "      <td>['Cooking &amp; Baking', 'Syrups', ' Sugars &amp; Swee...</td>\n",
       "      <td>29.48</td>\n",
       "      <td>29.48</td>\n",
       "      <td>['liquid vegetable fiber', 'caramel', 'monk fr...</td>\n",
       "      <td>[vegetfiber, caramel, monkfruitextract, carame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>2859</td>\n",
       "      <td>Thick-It Aquacare H2O Nectar Consistency Thick...</td>\n",
       "      <td>THICK-IT</td>\n",
       "      <td>['Fruit Juice', 'Grocery &amp; Gourmet Food', 'Hea...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>35.48</td>\n",
       "      <td>['artesian mineral water', 'xanthan gum', 'pot...</td>\n",
       "      <td>[artesianminerwater, xanthangum, potassiumsorb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>8793</td>\n",
       "      <td>Gerber 2nd Foods Pears</td>\n",
       "      <td>Gerber</td>\n",
       "      <td>['Baby &amp; Child', 'Cereal and Food', 'Food and ...</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.99</td>\n",
       "      <td>['ascorbic acid', 'pear puree concentrate', 'c...</td>\n",
       "      <td>[ascorbacid, pear, citricacid, pearwater, pear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>1849</td>\n",
       "      <td>Keto Queen Kreations</td>\n",
       "      <td>Keto Queen Kreations</td>\n",
       "      <td>['Coffeecakes', 'Grocery &amp; Gourmet Food', 'Cak...</td>\n",
       "      <td>12.99</td>\n",
       "      <td>12.99</td>\n",
       "      <td>['coconut flour', 'erythritol', 'baking powder']</td>\n",
       "      <td>[coconutflour, erythritol, bake]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9350 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               name  \\\n",
       "0       4184  BANQUET Frozen Chicken Breast Patties Made Wit...   \n",
       "1       4487                   COLMANS Original English Mustard   \n",
       "2       4137               Against The Grain Three Cheese Pizza   \n",
       "4       1381                  NESTLE COFFEE-MATE Coffee Creamer   \n",
       "5       1493                                   Planters Peanuts   \n",
       "...      ...                                                ...   \n",
       "10991   9828                            Merenda Hazelnut Spread   \n",
       "10992  10380                                       Honest Syrup   \n",
       "10993   2859  Thick-It Aquacare H2O Nectar Consistency Thick...   \n",
       "10994   8793                             Gerber 2nd Foods Pears   \n",
       "10999   1849                               Keto Queen Kreations   \n",
       "\n",
       "                      brand  \\\n",
       "0                   Banquet   \n",
       "1                  Colman's   \n",
       "2         Against The Grain   \n",
       "4        Nestle Coffee Mate   \n",
       "5                  Planters   \n",
       "...                     ...   \n",
       "10991              Pavlidis   \n",
       "10992              ChocZero   \n",
       "10993              THICK-IT   \n",
       "10994                Gerber   \n",
       "10999  Keto Queen Kreations   \n",
       "\n",
       "                                              categories  price_max  \\\n",
       "0      ['Grocery', 'Grocery & Gourmet Food', 'Breast ...       5.39   \n",
       "1      ['Grocery & Gourmet Food', 'English Mustard', ...      19.73   \n",
       "2          ['Pizza', 'Grocery & Gourmet Food', 'Frozen']     100.32   \n",
       "4      ['Grocery & Gourmet Food', 'Dairy', ' Cheese &...      22.72   \n",
       "5      ['Grocery', 'Cooking & Baking', 'Nuts & Trail ...       9.99   \n",
       "...                                                  ...        ...   \n",
       "10991  ['Jams', ' Jellies & Sweet Spreads', 'Grocery ...      13.10   \n",
       "10992  ['Cooking & Baking', 'Syrups', ' Sugars & Swee...      29.48   \n",
       "10993  ['Fruit Juice', 'Grocery & Gourmet Food', 'Hea...      40.00   \n",
       "10994  ['Baby & Child', 'Cereal and Food', 'Food and ...       2.09   \n",
       "10999  ['Coffeecakes', 'Grocery & Gourmet Food', 'Cak...      12.99   \n",
       "\n",
       "       price_min                                        ingredients  \\\n",
       "0           3.88  ['water', 'sodium bicarbonate', 'yeast', 'corn...   \n",
       "1           4.49  ['water', 'mustard flour', 'sugar', 'salt', 'w...   \n",
       "2         100.32  ['crust tapioca starch', 'milk', 'eggs', 'cano...   \n",
       "4          17.48  ['water', 'sugar', 'coconut oil', 'sodium case...   \n",
       "5           9.95  ['peanut andor cottonseed oil', 'peanuts', 'al...   \n",
       "...          ...                                                ...   \n",
       "10991      13.10  ['sugar', 'peanut oil', 'hazelnuts', 'skim mil...   \n",
       "10992      29.48  ['liquid vegetable fiber', 'caramel', 'monk fr...   \n",
       "10993      35.48  ['artesian mineral water', 'xanthan gum', 'pot...   \n",
       "10994       1.99  ['ascorbic acid', 'pear puree concentrate', 'c...   \n",
       "10999      12.99   ['coconut flour', 'erythritol', 'baking powder']   \n",
       "\n",
       "                                        ingredients_list  \n",
       "0      [water, sodiumbicarbon, yeast, cornstarch, whe...  \n",
       "1      [water, mustardflour, sugar, salt, wheatflour,...  \n",
       "2      [crusttapiocastarch, milk, egg, canolaoil, che...  \n",
       "4      [water, sugar, coconutoil, sodiumcasein, dipot...  \n",
       "5      [peanutcottonseoil, peanut, almond, cashew, pi...  \n",
       "...                                                  ...  \n",
       "10991     [sugar, peanutoil, hazelnut, milk, cocoa, soy]  \n",
       "10992  [vegetfiber, caramel, monkfruitextract, carame...  \n",
       "10993  [artesianminerwater, xanthangum, potassiumsorb...  \n",
       "10994  [ascorbacid, pear, citricacid, pearwater, pear...  \n",
       "10999                   [coconutflour, erythritol, bake]  \n",
       "\n",
       "[9350 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if STEM:\n",
    "    ps = PorterStemmer()\n",
    "    words = [ps.stem(word) for word in INGREDIENT_TO_REPLACE.split(' ')]\n",
    "    s = ''\n",
    "    for word in words:\n",
    "        s += word\n",
    "\n",
    "if REPLACE:\n",
    "    with open('replace_words.json') as f:\n",
    "        replacements = json.load(f)\n",
    "        for each in replacements.keys():\n",
    "            replacements[each] = ast.literal_eval(replacements[each])\n",
    "    \n",
    "if LOAD_SUB_FROM_FILE:\n",
    "    df = pd.read_csv('final_saved_balanced_dataset.csv')\n",
    "else:\n",
    "    files = [\n",
    "        \"outputs/food_1_Y.csv\",\n",
    "        \"outputs/food_2_Y.csv\",\n",
    "        \"outputs/food_3_Y.csv\"\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "    #df = df[df.index < int(len(df.index)/50)]\n",
    "    df = df.sample(frac=SUBSET_PERC, random_state=123456789)\n",
    "    #df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "\n",
    "with open('stopwords.txt', 'r') as f:\n",
    "    stopwords = []\n",
    "    for l in f:\n",
    "        if l not in stopwords:\n",
    "            stopwords.append(l.replace('\\n',''))\n",
    "#Add a list of the ingredients, and concatenate palm oil products to be just palm oil\n",
    "ingredients = [[x.lower() for x in ast.literal_eval(product['ingredients'])] for _,product in df.iterrows()]\n",
    "df['ingredients_list'] = ingredients\n",
    "\n",
    "\n",
    "\n",
    "drop_sparse_idx = []\n",
    "c = []\n",
    "banned_words = ['nan', 'none', 'na']\n",
    "trans = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "for row_idx, row in tqdm(df.iterrows()):\n",
    "    if row['brand'] == math.nan:\n",
    "        drop_sparse_idx.append(row_idx)\n",
    "    len_ing = len(row['ingredients_list'])\n",
    "    if len_ing==0:\n",
    "        drop_sparse_idx.append(row_idx)\n",
    "    elif len_ing == 1 and row['ingredients_list'][0].lower() in banned_words:\n",
    "        drop_sparse_idx.append(row_idx)\n",
    "    else:        \n",
    "        idx = 0\n",
    "        idx_to_remove = []\n",
    "        while idx<len(row['ingredients_list']):\n",
    "            if idx>1000:\n",
    "                print(row['ingredients_list'][idx])\n",
    "            row['ingredients_list'][idx] = row['ingredients_list'][idx].translate(trans)           \n",
    "            if row['ingredients_list'][idx] in replacements.keys():\n",
    "                #NEED TO DO THIS. SIMPLE GET THE VALUES IN replacements. CAN'T APPEND IN LOOP, BUT YOU COULD DO A WHILE LOOP\n",
    "                idx_to_remove.append(idx)\n",
    "                row['ingredients_list'].extend(replacements[row['ingredients_list'][idx]])             \n",
    "            idx+=1\n",
    "        if REMOVE_REPLACE:\n",
    "            for i in reversed(idx_to_remove):\n",
    "                row['ingredients_list'].pop(i)\n",
    "\n",
    "df = df.drop(drop_sparse_idx)\n",
    "drop_sparse_idx = []\n",
    "for row_idx, row in tqdm(df.iterrows()):\n",
    "    pop_li = []\n",
    "    for idx, each in enumerate(row['ingredients_list']):\n",
    "        stop_row_li = np.array(row['ingredients_list'][idx].split(' '))\n",
    "        for stopword in stopwords:\n",
    "            stop_loc = np.where(stop_row_li ==stopword)\n",
    "            if len(stop_loc[0])>0:\n",
    "                stop_row_li= np.delete(stop_row_li,stop_loc)\n",
    "                str_ = ''\n",
    "                for stringify_ in stop_row_li:\n",
    "                    str_ += ' ' + stringify_\n",
    "                row['ingredients_list'][idx] = str_\n",
    "        if STEM:\n",
    "            sentence = row['ingredients_list'][idx]\n",
    "            words = [ps.stem(word) for word in sentence.split(' ')]\n",
    "            s = ''\n",
    "            for word in words:\n",
    "                s += word\n",
    "            row['ingredients_list'][idx] = s\n",
    "            row['ingredients_list'][idx] = row['ingredients_list'][idx].replace(' ', '')\n",
    "        if row['ingredients_list'][idx] == '':\n",
    "            pop_li.append(idx)\n",
    "        else:\n",
    "            each = row['ingredients_list'][idx]\n",
    "            if all(item in each.lower() for item in INGREDIENT_TO_REPLACE.lower().split()):\n",
    "                c.append(each.lower())\n",
    "                row['ingredients_list'][idx] = INGREDIENT_TO_REPLACE.lower()\n",
    "    if pop_li:\n",
    "        for each in reversed(pop_li):\n",
    "            row['ingredients_list'].pop(each)\n",
    "        if len(row['ingredients_list']) == 0:\n",
    "            drop_sparse_idx.append(row_idx)\n",
    "\n",
    "df = df.drop(drop_sparse_idx)\n",
    "\n",
    "df = df[['index', 'name','brand','categories','price_max','price_min','ingredients','ingredients_list']]\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724812834224599 1.0\n"
     ]
    }
   ],
   "source": [
    "brand = {}\n",
    "num_palm = 0\n",
    "for idx,row in df.iterrows():\n",
    "    for each in row['ingredients_list']:\n",
    "        if INGREDIENT_TO_REPLACE in each.lower():\n",
    "            #print(\"Name: %s ## Ingredient: %s\" % (row['name'], each))            \n",
    "            num_palm += 1\n",
    "            br = row['brand']\n",
    "            brand[br] = brand[br] + 1 if br in brand.keys() else 1\n",
    "print(num_palm/len(df.index), len(df.index)/len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[[\"name\", \"ingredients\"]]\n",
    "df = df.drop_duplicates(subset=\"name\")\n",
    "df = df.reset_index()\n",
    "\n",
    "\n",
    "#unique_ingred = np.unique(sum(df[\"ingredients\"].apply(ast.literal_eval).values.tolist(), []))\n",
    "unique_names = df['name'].unique()\n",
    "unique_brands = df['brand'].unique()\n",
    "#unique_mans = df['manufacturer'].unique()\n",
    "unique_cats = np.unique(sum(df[\"categories\"].apply(ast.literal_eval).values.tolist(), []))\n",
    "unique_names = sorted(unique_names)\n",
    "#unique_ingred = sorted(unique_ingred)\n",
    "\n",
    "unique_ingred = []\n",
    "for x in df['ingredients_list']:\n",
    "    for y in x:\n",
    "        if y not in unique_ingred:\n",
    "            unique_ingred.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, SAGEConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_auc_score,precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector_and_label(product, decision_ingredients):\n",
    "  #Build feature vector of high entropy ingredients. \n",
    "  feature_vector = np.zeros(len(decision_ingredients))\n",
    "  ingredients = product['ingredients_list']#ast.literal_eval(product['ingredients'])\n",
    "  for dec_idx,decision_ingr in enumerate(decision_ingredients):\n",
    "    #Check if ingredients is in feature list, and also make sure to mask the palm oil ingredient\n",
    "    if unique_ingred[dec_idx] in ingredients and unique_ingred[dec_idx] != INGREDIENT_TO_REPLACE:      \n",
    "      feature_vector[dec_idx] = 1\n",
    "  #1 = palmy, 0 = non_palmy\n",
    "  label = 1 if INGREDIENT_TO_REPLACE in ingredients else 0\n",
    "\n",
    "  return (feature_vector, label)\n",
    "\n",
    "def get_cat_and_price(product):\n",
    "  #get category data\n",
    "  cat_data = ast.literal_eval(product['categories'])\n",
    "  #Get mean price\n",
    "  price_data = (product['price_min']+product['price_max']) / 2\n",
    "  return {'cat':cat_data, 'price':price_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_matrix_from_features(feature_mat):\n",
    "    adj_mat = np.zeros((len(unique_names), len(unique_names)), dtype=int)\n",
    "    for idx, col in enumerate(feature_mat.T):\n",
    "        elements = np.where(col==1)[0]\n",
    "        for i in elements:\n",
    "            for j in elements:\n",
    "                adj_mat[i,j] += 1 if i!=j else 0 \n",
    "    return adj_mat\n",
    "\n",
    "def get_adj_matrix_from_extra_features(feature_mat):\n",
    "    adj_mat = np.zeros((len(unique_names), len(unique_names)), dtype=int)\n",
    "    shared_features = np.zeros((len(unique_names), len(unique_names)), dtype=int)\n",
    "    for idx, col in enumerate(feature_mat.T):\n",
    "        elements = np.where(col==1)[0]\n",
    "        for i in elements:\n",
    "            for j in elements:\n",
    "                adj_mat[i,j] += 1 if i!=j else 0\n",
    "                shared_features[i,j] = idx\n",
    "    return (adj_mat, shared_features)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_matrix():\n",
    "    feature_mat = np.zeros((len(unique_names),len(unique_ingred)),dtype=int)\n",
    "    for idx, row in df.iterrows():\n",
    "        ingr = row['ingredients_list']\n",
    "        for ing_idx,each in enumerate(unique_ingred):\n",
    "            feature_mat[idx,ing_idx] = 1 if each in ingr else 0\n",
    "    return feature_mat\n",
    "\n",
    "def get_feature_coocurrance():    \n",
    "    feature_mat = dict()\n",
    "    for each in range(len(unique_ingred)):\n",
    "        feature_mat[each] = np.zeros((len(unique_ingred)),dtype=int)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        ingr = row['ingredients_list']#ast.literal_eval(row['ingredients'])\n",
    "        for ing_idx,each in enumerate(unique_ingred):\n",
    "            if each in ingr:\n",
    "                for ing_idx2,each2 in enumerate(unique_ingred):\n",
    "                    if each2 in ingr:\n",
    "                        #Minus the value along the diagonal. Prevents inteference with the coocurrance but also allows us to retrieve magnitude later\n",
    "                        feature_mat[ing_idx][ing_idx2] += 1 if ing_idx!=ing_idx2 else -1\n",
    "    return feature_mat\n",
    "\n",
    "def get_information_entropy(cooccurance_matrix, palm_oil_idx, num_palm_oil, num_total_products):\n",
    "    #Intuition: use information entropy to calculate how much information each other ingredient can give us on the presence of palm oil\n",
    "    # - (P(palm_oil_presence|x) log(P(palm_oil_presence|x))) + (P(¬palm_oil_presence|x) log(P(¬palm_oil_presence|x)))\n",
    "    def calculate_entropy(palm_presence, n):\n",
    "        if n != 0:\n",
    "            p1 = palm_presence/n\n",
    "        else:\n",
    "            p1 = 0\n",
    "        p2 = 1-p1\n",
    "        sum1 = 0 if p1==0 else (p1*math.log2(p1))\n",
    "        sum2 = 0 if p2==0 else (p2*math.log2(p2))\n",
    "        return - sum1 + sum2\n",
    "    \n",
    "    def calcalate_conditional_entropy(palm_presence, n, p_n):\n",
    "        if p_n < 0:\n",
    "            print(p_n)\n",
    "            exit()\n",
    "        if n!= 0:\n",
    "            p1 = (palm_presence/n)*p_n\n",
    "        else:\n",
    "            p1 = 0\n",
    "        assert p1 >=0\n",
    "        assert p_n >=0\n",
    "        sum1 = 1 if (p1<=0 or p_n<=0) else (1 + (p1*math.log2(1+(p1/p_n))))\n",
    "        if sum1 <= 0:\n",
    "            print(p1, p_n, palm_presence, n)\n",
    "        return sum1\n",
    "\n",
    "    n = len(unique_ingred)\n",
    "    entropies = np.empty(n) \n",
    "    for idx,each in enumerate(cooccurance_matrix[palm_oil_idx]):\n",
    "        if idx == palm_oil_idx:\n",
    "            entropies[idx] == 100\n",
    "        else:\n",
    "            n_occ = -cooccurance_matrix[idx][idx]\n",
    "            assert n_occ >= each, (unique_ingred[idx])\n",
    "            entropies[idx] = (calcalate_conditional_entropy(each, n_occ, n_occ/num_total_products) + \n",
    "                                calcalate_conditional_entropy(each, num_total_products-n_occ, (num_total_products-n_occ)/num_total_products) + \n",
    "                                calcalate_conditional_entropy(n_occ-each, n_occ, n_occ/num_total_products) + \n",
    "                                calcalate_conditional_entropy(n_occ-each, num_total_products-n_occ, (num_total_products-n_occ)/num_total_products)\n",
    "                                )\n",
    "    return entropies\n",
    "\n",
    "def frequency_weighted_conditional_entropies(cooccurance_matrix, ordered_entropy, entropies):\n",
    "  frequency_weighted_conditional_entropies = []\n",
    "  total_products = len(df.index)\n",
    "  fs = []\n",
    "  min_frequency = 0.00\n",
    "  for idx in ordered_entropy:\n",
    "      #Minus as you've made the diagonal minus for other reasons      \n",
    "      if cooccurance_matrix[idx][idx]!=0:\n",
    "          frequency = (-cooccurance_matrix[idx][idx])/total_products\n",
    "          fs.append(frequency)\n",
    "          if frequency >= min_frequency:\n",
    "              occurance = np.log(1/frequency)\n",
    "              if occurance < 0:\n",
    "                  print(\"yes\")\n",
    "              \n",
    "              frequency_weighted_conditional_entropies.append(occurance*entropies[idx])\n",
    "          else:\n",
    "              frequency_weighted_conditional_entropies.append(1.0)\n",
    "  return frequency_weighted_conditional_entropies\n",
    "\n",
    "def apply_entropy_mask(feature_matrix,top_n=2000, frequency_weighted=True):\n",
    "  cooccurance_matrix = get_feature_coocurrance()\n",
    "  #Print the highest co-occuring ingredients\n",
    "  for idx,each in enumerate(unique_ingred):\n",
    "      if (INGREDIENT_TO_REPLACE in each.lower()):\n",
    "          palm_idx = idx\n",
    "          palm_vector = cooccurance_matrix[idx]\n",
    "          sorted_indicies = sorted(range(len(palm_vector)), key=lambda x: palm_vector[x], reverse=True)\n",
    "          print(\"MOST CO-OCCURANCES: \",[(unique_ingred[x],palm_vector[x]) for x in sorted_indicies[:10]])\n",
    "          break\n",
    "  entropies = get_information_entropy(cooccurance_matrix, palm_idx, num_palm,len(df.index))\n",
    "  ordered_entropy = sorted(range(len(entropies)), key=lambda x: entropies[x], reverse=False)\n",
    "  \n",
    "  if frequency_weighted:\n",
    "    fwce = frequency_weighted_conditional_entropies(cooccurance_matrix, ordered_entropy, entropies)\n",
    "    fwce_ordered_entropy = sorted(range(len(entropies)), key=lambda x: fwce[x], reverse=False)\n",
    "    unique_ingred_ = [unique_ingred[i_] for i_ in fwce_ordered_entropy[:top_n]]\n",
    "    feature_matrix = get_feature_matrix() \n",
    "    return feature_matrix, fwce_ordered_entropy, unique_ingred_\n",
    "  else:\n",
    "    unique_ingred_ = [unique_ingred[i_] for i_ in ordered_entropy[:top_n]]\n",
    "    feature_matrix = get_feature_matrix() \n",
    "    return feature_matrix, ordered_entropy, unique_ingred_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4538/4538 [46:22<00:00,  1.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4538, 8945], edge_index=[2, 224505], y=[4538], edge_label=[224505], edge_label_index=[2, 224505])\n",
      "tensor([[1228, 1997, 1707,  233, 2171, 2258, 2184, 1336, 1938, 2185],\n",
      "        [2498, 4115, 2433, 4413, 3350, 3650, 3417, 3230, 4093, 2667]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def get_balanced_dataset(df):\n",
    "  df = df.drop('level_0', axis=1).reset_index()\n",
    "  palmy_prods = []\n",
    "  for idx,row in df.iterrows():\n",
    "    for each in row['ingredients_list']:    \n",
    "      if (INGREDIENT_TO_REPLACE in each):\n",
    "        palmy_prods.append(row)\n",
    "\n",
    "  palmy_df = pd.DataFrame(palmy_prods)\n",
    "  #Sample the same amount of non-palmy products\n",
    "\n",
    "  df = df.drop(list(palmy_df.index))\n",
    "  palmy_df = palmy_df.drop_duplicates(subset='index')\n",
    "  sample_len = len(palmy_df.index)\n",
    "  non_palmy_df = df.sample(sample_len)\n",
    "  assert len(palmy_df.index) == len(non_palmy_df.index)\n",
    "  frame = pd.concat([palmy_df, non_palmy_df]).drop('level_0', axis=1)\n",
    "  frame = frame.reset_index().drop('level_0', axis=1)\n",
    "  return frame\n",
    "\n",
    "if USE_STANDARD_DATA:\n",
    "  df = pd.read_csv(root_to_standard_data,converters={'ingredients_list': pd.eval})\n",
    "elif SAVE_STANDARD_DATA:\n",
    "  df = get_balanced_dataset(df)\n",
    "  df.to_csv(root_to_standard_data)\n",
    "# else:\n",
    "#   df = get_balanced_dataset(df)\n",
    "\n",
    "unique_ingred = []\n",
    "for x in df['ingredients_list']:\n",
    "    for y in x:\n",
    "        if y not in unique_ingred:\n",
    "            unique_ingred.append(y)\n",
    "\n",
    "#Don't need ingredients, now that we have the ingredients list column\n",
    "df = df.drop('ingredients', axis=1)\n",
    "#Get Matrix of Features -- Products x Features\n",
    "feature_matrix = []\n",
    "label_vector = []\n",
    "for idx, product in df.iterrows():\n",
    "  feature_vector, label = get_feature_vector_and_label(product, unique_ingred)#get_feature_vector_and_label_with_brands(product, unique_ingred)\n",
    "  feature_matrix.append(feature_vector)\n",
    "  label_vector.append(label)\n",
    "\n",
    "\n",
    "\n",
    "if MASK:\n",
    "  feature_matrix,ordered_entropy,unique_ingred=apply_entropy_mask(feature_matrix,int(len(unique_ingred)/2), frequency_weighted=USE_FREQUENCY)\n",
    "\n",
    "feature_matrix = []\n",
    "label_vector = []\n",
    "for idx, product in df.iterrows():\n",
    "  feature_vector, label = get_feature_vector_and_label(product, unique_ingred)#get_feature_vector_and_label_with_brands(product, unique_ingred)\n",
    "  feature_matrix.append(feature_vector)\n",
    "  label_vector.append(label)\n",
    "feature_matrix = torch.tensor(feature_matrix, dtype=torch.float)\n",
    "label_vector = torch.tensor(label_vector)\n",
    "\n",
    "#Get The category and price information for each node. Used to define edges\n",
    "node_data_for_edges = np.array([get_cat_and_price(product) for _, product in df.iterrows()])\n",
    "edge_index = []\n",
    "edge_data = []\n",
    "price_range = 0.1 #Prices must be within 20%\n",
    "for from_ in tqdm(range(len(node_data_for_edges))):\n",
    "  row = df.iloc[[from_]]\n",
    "  for r in row['ingredients_list']:\n",
    "    for each in r:\n",
    "      if each==INGREDIENT_TO_REPLACE:\n",
    "        #if 'palm oil' in list(df.iloc[[from_]]['ingredients_list']):\n",
    "        for to_ in range(len(node_data_for_edges)):\n",
    "          is_palm = False\n",
    "          for to_row in df.loc[[to_]]['ingredients_list']:\n",
    "            for to_each in to_row:\n",
    "              if to_each == INGREDIENT_TO_REPLACE:\n",
    "                is_palm = True\n",
    "          if not is_palm:\n",
    "            #Check if they are similar price\n",
    "            price_ratio = node_data_for_edges[from_]['price']/node_data_for_edges[to_]['price']\n",
    "            if (price_ratio >= 1-price_range) and (price_ratio <= 1+price_range):\n",
    "              #Check if they are in the same category\n",
    "              for cat_ in node_data_for_edges[from_]['cat']:\n",
    "                if cat_ in node_data_for_edges[to_]['cat']:\n",
    "                  if from_ == to_:\n",
    "                    print(df.iloc[[to_]])\n",
    "                  edge_index.append([from_, to_])\n",
    "                  edge_data.append([cat_, price_ratio])\n",
    "                  #TODO IMPORTANT: WILL ONLY EVER USE 1 CATEGORY HERE. EVEN IF MULTIPLE ARE SHARED\n",
    "                  break\n",
    "        break\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "#edge_data = torch.tensor(edge_data)\n",
    "transform = T.Compose([\n",
    "  T.ToDevice(device),\n",
    "  T.RandomLinkSplit(num_val=0.1,num_test=0.1,is_undirected=False, add_negative_train_samples=False)  \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data, val_data, test_data = transform(Data(x=feature_matrix, y=label_vector,edge_index=edge_index))\n",
    "\n",
    "#dataset = ProductDataset(data, transform=transform)\n",
    "#dataloader = DataLoader(dataset, \n",
    "print(data)\n",
    "print(data.edge_index[:,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1228, 1997, 1707,  233, 2171, 2258, 2184, 1336, 1938, 2185],\n",
      "        [2498, 4115, 2433, 4413, 3350, 3650, 3417, 3230, 4093, 2667]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index[:,:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "class SAGENet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "    def get_links(self, z, edge_label_index):\n",
    "        decoded = self.decode(z, edge_label_index).view(-1).sigmoid()\n",
    "        preds = torch.Tensor([0 if x<0.5 else 1 for x in decoded]).to(device)\n",
    "        print(preds.shape)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = len(data.x[0])\n",
    "\n",
    "# model = SAGENet(num_features, 128, 64).to(device)\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#       model.train()\n",
    "#       optimizer.zero_grad()  # Clear gradients.\n",
    "#       #palm_oil_mask = np.where(data.y.cpu().numpy()==1)[0]\n",
    "#       # data_edge_index = data.edge_index[palm_oil_mask]\n",
    "#       # data_edge_label = data.edge_label[palm_oil_mask]\n",
    "#       # data_edge_label_index = data.edge_label_index[palm_oil_mask]\n",
    "      \n",
    "      \n",
    "#       z=model.encode(data.x, data.edge_index)\n",
    "#       #print(data.edge_index.size(),data.edge_label.size(1),len(data.x))\n",
    "#       neg_edge_index = negative_sampling(edge_index=data.edge_index, num_nodes=len(data.x), num_neg_samples=data.edge_label_index.size(1), method=\"sparse\")\n",
    "#       edge_label_index = torch.cat([data.edge_label_index, neg_edge_index], dim=-1)\n",
    "#       edge_label = torch.cat([data.edge_label, data.edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "\n",
    "\n",
    "#       out = model.decode(z,edge_label_index).view(-1)\n",
    "#       loss = criterion(out,edge_label)\n",
    "#       # out = model.decode(z,data.edge_label_index).view(-1)\n",
    "#       # loss = criterion(out, data.edge_label)\n",
    "#       loss.backward()\n",
    "#       optimizer.step()\n",
    "#       preds = out.cpu().detach().numpy()\n",
    "#       preds = np.array([0 if x<0.5 else 1 for x in preds])\n",
    "#       acc =  float(len(np.where(preds==edge_label.cpu().numpy())[0]))/len(preds)\n",
    "#       return loss\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def test():\n",
    "#       model.eval()\n",
    "#       z = model.encode(test_data.x, test_data.edge_index)\n",
    "#       neg_edge_index = negative_sampling(edge_index=test_data.edge_index, num_nodes=len(test_data.x), num_neg_samples=test_data.edge_label_index.size(1), method=\"sparse\")\n",
    "#       edge_label_index = torch.cat([test_data.edge_label_index, neg_edge_index], dim=-1)\n",
    "#       edge_label = torch.cat([test_data.edge_label, test_data.edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "#       out = model.decode(z, edge_label_index).view(-1).sigmoid()\n",
    "      \n",
    "#       preds = out.cpu().numpy()\n",
    "#       preds = np.array([0 if x<0.5 else 1 for x in preds])\n",
    "#       el = edge_label.cpu().numpy()\n",
    "#       o =  out.cpu().numpy()\n",
    "#       acc =  float(len(np.where(preds==edge_label.cpu().numpy())[0]))/len(preds)\n",
    "#       #print(len(np.where(o>=0.5)[0]), len(np.where(o<=0.5)[0]), len(o))\n",
    "#       return roc_auc_score(edge_label.cpu().numpy(), out.cpu().numpy()), acc      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for epoch in range(1,500):\n",
    "# #       loss=train()\n",
    "# #       test_auc, acc = test()\n",
    "# #       print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "# #             f'Test AUC: {test_auc:.4f}', f'Test ACC: {acc:.4f}')\n",
    "\n",
    "# # torch.save(model.state_dict(), './model_saves/link_pred/link_prediction_sage_model')\n",
    "\n",
    "# # z = model.encode(test_data.x, test_data.edge_index)\n",
    "# # final_edge_index = model.decode_all(z)\n",
    "# # final_data = deepcopy(test_data)\n",
    "# # final_data.edge_index = final_edge_index\n",
    "\n",
    "\n",
    "# # def test():\n",
    "# #       class_correct = [0,0]\n",
    "# #       class_samples = [0,0]\n",
    "# #       model.eval()\n",
    "# #       out = model(data.x, data.edge_index, data.edge_weight)\n",
    "# #       pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "# #       test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "# #       assert len(test_correct)==len(pred[data.test_mask])\n",
    "# #       #print(test_correct)\n",
    "# #       test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "# #       p = pred[data.test_mask]\n",
    "# #       d = data.y[data.test_mask]\n",
    "      \n",
    "# #       for idx,each in enumerate(test_correct):          \n",
    "# #           class_samples[p[idx]] += 1\n",
    "# #           if each == True:\n",
    "# #               class_correct[p[idx]] += 1\n",
    "# #       print(class_correct, class_samples)\n",
    "# #       print([class_correct[idx]/class_samples[idx] for idx in range(2)])\n",
    "# #       return test_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualise random sample\n",
    "# k = 100\n",
    "# #Ground Truth Graph\n",
    "# new_graph = to_networkx(test_data)\n",
    "# print(len(new_graph.edges))\n",
    "# sampled_nodes = random.sample(new_graph.nodes, k)\n",
    "# nx.draw(new_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predicted Graph\n",
    "\n",
    "# new_graph = to_networkx(final_data)\n",
    "# sampled_graph = new_graph.subgraph(sampled_nodes)\n",
    "# nx.draw(sampled_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 7.48 GiB (GPU 0; 8.00 GiB total capacity; 180.87 MiB already allocated; 6.34 GiB free; 202.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26600/1773856187.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[0mlrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gridsearch/link/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26600/1773856187.py\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(hidden_channels, out_channels, lrs, save_path)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mstop_at\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m501\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m               \u001b[0mloss_li\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26600/1773856187.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(optimizer, criterion)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m       \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m       \u001b[1;31m#print(data.edge_index.size(),data.edge_label.size(1),len(data.x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[0mneg_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnegative_sampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_neg_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_label_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sparse\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26600/55709118.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# Otherwise, run both functions in separation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             coll_dict = self.__collect__(self.__user_args__, edge_index, size,\n\u001b[0m\u001b[0;32m    262\u001b[0m                                          kwargs)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36m__collect__\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_size__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                     data = self.__lift__(data, edge_index,\n\u001b[0m\u001b[0;32m    172\u001b[0m                                          j if arg[-2:] == '_j' else i)\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36m__lift__\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.48 GiB (GPU 0; 8.00 GiB total capacity; 180.87 MiB already allocated; 6.34 GiB free; 202.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\n",
    "def grid_search(hidden_channels:list, out_channels:list,lrs:list,save_path:str):\n",
    "    def train(optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      #palm_oil_mask = np.where(data.y.cpu().numpy()==1)[0]\n",
    "      # data_edge_index = data.edge_index[palm_oil_mask]\n",
    "      # data_edge_label = data.edge_label[palm_oil_mask]\n",
    "      # data_edge_label_index = data.edge_label_index[palm_oil_mask]\n",
    "      \n",
    "      \n",
    "      z=model.encode(data.x, data.edge_index)\n",
    "      #print(data.edge_index.size(),data.edge_label.size(1),len(data.x))\n",
    "      neg_edge_index = negative_sampling(edge_index=data.edge_index, num_nodes=len(data.x), num_neg_samples=data.edge_label_index.size(1), method=\"sparse\")\n",
    "      edge_label_index = torch.cat([data.edge_label_index, neg_edge_index], dim=-1)\n",
    "      edge_label = torch.cat([data.edge_label, data.edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "\n",
    "\n",
    "      out = model.decode(z,edge_label_index).view(-1)\n",
    "      loss = criterion(out,edge_label)\n",
    "      # out = model.decode(z,data.edge_label_index).view(-1)\n",
    "      # loss = criterion(out, data.edge_label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      preds = out.cpu().detach().numpy()\n",
    "      preds = np.array([0 if x<0.5 else 1 for x in preds])\n",
    "      acc =  float(len(np.where(preds==edge_label.cpu().numpy())[0]))/len(preds)\n",
    "      return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "          model.eval()\n",
    "          z = model.encode(test_data.x, test_data.edge_index)\n",
    "          neg_edge_index = negative_sampling(edge_index=test_data.edge_index, num_nodes=len(test_data.x), num_neg_samples=test_data.edge_label_index.size(1), method=\"sparse\")\n",
    "          edge_label_index = torch.cat([test_data.edge_label_index, neg_edge_index], dim=-1)\n",
    "          edge_label = torch.cat([test_data.edge_label, test_data.edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "          out = model.decode(z, edge_label_index).view(-1).sigmoid()\n",
    "          \n",
    "          preds = out.cpu().numpy()\n",
    "          preds = np.array([0 if x<0.5 else 1 for x in preds])\n",
    "          el = edge_label.cpu().numpy()\n",
    "          acc =  float(len(np.where(preds==edge_label.cpu().numpy())[0]))/len(preds)\n",
    "\n",
    "          f1 = f1_score(edge_label.cpu().numpy(), preds)\n",
    "\n",
    "          #print(len(np.where(o>=0.5)[0]), len(np.where(o<=0.5)[0]), len(o))\n",
    "          return roc_auc_score(edge_label.cpu().numpy(), out.cpu().numpy()), acc, f1\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def val():\n",
    "          model.eval()\n",
    "          z = model.encode(test_data.x, val_data.edge_index)\n",
    "          neg_edge_index = negative_sampling(edge_index=val_data.edge_index, num_nodes=len(val_data.x), num_neg_samples=val_data.edge_label_index.size(1), method=\"sparse\")\n",
    "          edge_label_index = torch.cat([val_data.edge_label_index, neg_edge_index], dim=-1)\n",
    "          edge_label = torch.cat([val_data.edge_label, val_data.edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "          out = model.decode(z, edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "          preds = out.cpu().numpy()\n",
    "          preds = np.array([0 if x<0.5 else 1 for x in preds])\n",
    "          el = edge_label.cpu().numpy()\n",
    "          o =  out.cpu().numpy()\n",
    "\n",
    "          f1 = f1_score(edge_label.cpu().numpy(), preds)\n",
    "          \n",
    "\n",
    "          acc =  float(len(np.where(preds==edge_label.cpu().numpy())[0]))/len(preds)\n",
    "          #print(len(np.where(o>=0.5)[0]), len(np.where(o<=0.5)[0]), len(o))\n",
    "          return roc_auc_score(edge_label.cpu().numpy(), out.cpu().numpy()), acc,f1\n",
    "\n",
    "    num_features = len(data.x[0])\n",
    "    data_dict = {}\n",
    "    end_str = INGREDIENT_TO_REPLACE\n",
    "    data_dict[end_str] = {'train_loss':{}, 'Test Accuracy':{},'Test AUC':{}, 'Validation Accuracy':{}, 'Validation AUC':{}, 'Validation F1': {}, 'Test F1': {}}\n",
    "    for hidden_chans in hidden_channels:\n",
    "      for out_chans in out_channels:\n",
    "        for lr in lrs:\n",
    "          for i in range(25):\n",
    "            model = SAGENet(num_features, hidden_chans, out_chans).to(device)\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "            criterion = torch.nn.BCEWithLogitsLoss()\n",
    "            max_acc = 0.0\n",
    "            max_auc = 0.0\n",
    "            acc_li = []\n",
    "            auc_li = []\n",
    "            test_acc_li = []\n",
    "            test_auc_li = []\n",
    "            test_f1_li = []\n",
    "            val_f1_li = []\n",
    "            loss_li = []\n",
    "            stop_at = 0\n",
    "            for epoch in range(1,501):\n",
    "              loss=train(optimizer,criterion)         \n",
    "              loss_li.append(loss.cpu().detach().item())\n",
    "              if (epoch%10)==0 or epoch==1:\n",
    "                auc,acc,val_f1 = val()\n",
    "                acc_li.append(acc)\n",
    "                auc_li.append(auc)\n",
    "                val_f1_li.append(val_f1)\n",
    "                test_auc, test_acc,test_f1 = test()\n",
    "                test_acc_li.append(test_acc)\n",
    "                test_auc_li.append(test_auc)\n",
    "                test_f1_li.append(test_f1)\n",
    "                if acc > max_acc:\n",
    "                  stop_at = epoch\n",
    "                  max_auc = auc \n",
    "                  max_acc = acc \n",
    "              \n",
    "              # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              #       f'Test AUC: {test_auc:.4f}',f'Max AUC: {max_auc:.4f}')\n",
    "\n",
    "            print(f'{i} -- Hids: {hidden_chans} Outs: {out_chans} LR: {lr} Max AUC: {test_auc_li[int(stop_at/10)]:.4f} Max Acc: {test_acc_li[int(stop_at/10)]: .4f} Max F1: {test_f1_li[int(stop_at/10)]}')\n",
    "\n",
    "            data_dict[end_str]['train_loss'][i] = loss_li\n",
    "            data_dict[end_str]['Validation Accuracy'][i] = acc_li\n",
    "            data_dict[end_str]['Validation AUC'][i] = auc_li\n",
    "            data_dict[end_str]['Test Accuracy'][i] = test_acc_li\n",
    "            data_dict[end_str]['Test AUC'][i] = test_auc_li\n",
    "            data_dict[end_str]['Validation F1'][i] = val_f1_li\n",
    "            data_dict[end_str]['Test F1'][i] = test_f1_li\n",
    "            del(model)\n",
    "          with open(save_path+f'{INGREDIENT_TO_REPLACE}_data_dict_entropy_stop_{stop_at}', 'wb') as f:\n",
    "            pickle.dump(data_dict, f)\n",
    "      \n",
    "outs = [128] \n",
    "hids = [128] \n",
    "lrs = [0.001]\n",
    "save_path = 'gridsearch/link/'\n",
    "grid_search(hids,outs,lrs,save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_graph = to_networkx(final_data)\n",
    "# pos=nx.circular_layout(new_graph)\n",
    "# nx.draw(new_graph, pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.y)\n",
    "new_graph = to_networkx(data)\n",
    "pos=nx.kamada_kawai_layout(new_graph)\n",
    "\n",
    "k=20\n",
    "\n",
    "sampled_nodes = random.sample(new_graph.nodes,k)\n",
    "\n",
    "sampled_graph = new_graph.subgraph(sampled_nodes)\n",
    "\n",
    "print(nx.is_bipartite(sampled_graph))\n",
    "\n",
    "li = list(sampled_nodes)\n",
    "cm = []\n",
    "palm_list = []\n",
    "o_c, b_c = 0,0\n",
    "for node in sampled_graph:\n",
    "    if data.y[node] ==1:\n",
    "        cm.append('orange')\n",
    "        palm_list.append(node)\n",
    "        o_c+=1\n",
    "    else:\n",
    "        cm.append('blue')\n",
    "        b_c+=1\n",
    "\n",
    "pos=nx.bipartite_layout(sampled_graph, nodes=palm_list)\n",
    "nx.draw(sampled_graph, node_color=cm, pos=pos, edgecolors='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
